
# ChatWithLLM

Repositório criado para o ciclo de seminários da faculdade Ulbra Palmas-TO!

## Pré-requisitos

Antes de começar, certifique-se de ter os seguintes itens instalados:

- **Python** (Versão 3.12.5 ou superior)
- **Ollama**: Para instalar, visite [ollama.com](https://ollama.com) e siga as instruções para configurar a ferramenta e obter modelos de linguagem.

## Instalação

1. **Clone o projeto**

   Clone o repositório para sua máquina local usando o comando Git:

   ```bash
   git clone <git@github.com:mariannedutra/ChatWithLLM.git>
   ```

2. **Crie e ative um ambiente virtual**

   Navegue até o diretório do projeto e crie um ambiente virtual:

   ```bash
   python -m venv .venv
   ```

   Ative o ambiente virtual:

   - No Windows:
     ```bash
     .venv\Scripts\activate
     ```

   - No macOS/Linux:
     ```bash
     source .venv/bin/activate
     ```

3. **Instale as dependências**

   Com o ambiente virtual ativado, instale as dependências do projeto:

   ```bash
   pip install -r requirements.txt
   ```

## Inicie a aplicação

Com tudo configurado, você está pronto para iniciar a aplicação. Execute o comando:

```bash
streamlit run main.py
```

A aplicação estará disponível no seu navegador em [localhost:8501](http://localhost:8501).

---

Caso tenha alguma dúvida ou precise de ajuda, consulte a documentação ou entre em contato com o suporte.

